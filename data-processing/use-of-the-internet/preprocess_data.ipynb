{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDIVIDUALS - FREQUENCY OF INTERNET ACCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indic_is ( Statistic Indicator )\n",
    "I_IDAY: Frequency of internet access: daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC_IND (Unit of Measure )\n",
    "PC_IND: Percentage of individuals (and not for example enterprise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IND_TOTAL:All individuals ( and not only male or female )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path = \"original-datasets/freq/freq.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"original-datasets/freq/freq.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember : In the csv if the value related to the year is not present the row is not present !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDIVIDUALS - INTERNET ACTIVITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to combine different CSV coming from EUROSTAT and determine which activity is performed more .\n",
    "<br>\n",
    "The Datasets are the one related to : <br>\n",
    "- The percentage of people that use internet for good and services in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for partecipation in social network in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for selling good and services in EU country from 2013 to 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"original-datasets/activities/percentage_people_good_and_services.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"preprocessed_data/activities/percentage_people_good_and_services.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/activities/percentage_people_selling_good_and_services.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"preprocessed_data/activities/percentage_people_selling_good_and_services.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/activities/percentage_people_partecipating_in_social_network.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"preprocessed_data/activities/percentage_people_partecipating_in_social_network.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentual of individual of each country encountering Degrading Messages online in 2023 coming from NON-EU Country citizens (sub-divided for what they are discriminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS FLAG values: OBS_FLAG    3193\n",
      "dtype: int64 \n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    1\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in ind_type :\n",
      " ['Individuals who are born in another EU Member State'\n",
      " 'Individuals who are born in non-EU country'] \n",
      "\n",
      "NUMBER OF CATEGORIES in ind_type:\n",
      " 93 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\n",
      " Males, 20 to 24 years old                              621\n",
      "Individuals aged 55 to 74 with low formal education    621\n",
      "Individuals, 16 to 29 years old                        621\n",
      "Individuals aged 16-24 with medium formal education    621\n",
      "Individuals aged 16-24 with low education              621\n",
      "Name: ind_type, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in indic_is :\n",
      " ['Individuals who have encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of disability'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of political or social views'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of religion or belief'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of racial or ethnic origin'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sex'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sexual orientation (LGBTIQ identities)'] \n",
      "\n",
      "NUMBER OF CATEGORIES in indic_is:\n",
      " 8 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\n",
      " Individuals who believed that these groups of people were attacked/targeted because of disability                        7437\n",
      "Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics    7437\n",
      "Name: indic_is, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in unit :\n",
      " ['Percentage of individuals'\n",
      " 'Percentage of individuals who used internet in the last 3 months'\n",
      " 'Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'] \n",
      "\n",
      "NUMBER OF CATEGORIES in unit:\n",
      " 3 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\n",
      " Percentage of individuals                                                                                                                                                 19840\n",
      "Percentage of individuals who used internet in the last 3 months                                                                                                          19840\n",
      "Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months    17339\n",
      "Name: unit, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Austria' 'Belgium' 'Bulgaria' 'Cyprus' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'European Union - 27 countries (from 2020)' 'Finland'\n",
      " 'France' 'Croatia' 'Hungary' 'Lithuania' 'Luxembourg' 'Latvia' 'Malta'\n",
      " 'Netherlands' 'Poland' 'Portugal' 'Romania' 'Sweden' 'Slovenia'\n",
      " 'Slovakia' 'Switzerland' 'Norway'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 27 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Austria    2139\n",
      "Sweden     2139\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "counts = df[['OBS_FLAG']].count()\n",
    "print(\"OBS FLAG values: {} \".format(counts))\n",
    "\n",
    "counts = df[['CONF_STATUS']].count()\n",
    "print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "num_unique= df[['TIME_PERIOD']].nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "# quindi droppo le colonne non utili \n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"OBS_FLAG\",\"CONF_STATUS\",\"TIME_PERIOD\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"ind_type\" | 92 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA CHI è CHE VIENE DISCRIMNATO?\n",
    "\n",
    "coloumn  = df['ind_type']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in ind_type :\\n {} \\n\".format(counts[0:2]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in ind_type:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(5)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"indic_is\" | 8 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA per cosa si DISCRIMINA ?\n",
    "coloumn  = df['indic_is']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in indic_is :\\n {} \\n\".format(counts[:]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in indic_is:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 3 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA in che PERIODO DELL'ANNO 2023 SI DISCRIMINA\n",
    "\n",
    "coloumn  = df['unit']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in unit :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(3)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 27 CATEGORIE DIFFERENTI\n",
    "coloumn  = df['geo']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in geo :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in geo:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# Ora : dato che il numero di categorie in IND_TYPE è 93 \n",
    "# ( non prendo tutti gli individui ma solo 2 categorie  )\n",
    "# e il numero di categorie in INDIC_IS è 8 \n",
    "# e il numero di categorie in unit è 3 ( e droppo la colonna no , prendo solo precentage of individual quello totale\")\n",
    "\n",
    "# Filtra il dataframe per la categorie specifiche che è una \"Individuals who are born in non-EU country\"\n",
    "# RISPONDE ALLA DOMANDA CHI VIENE DISCRIMINATO ?\n",
    "df = df[df['ind_type'].isin([\"Individuals who are born in non-EU country\"])]\n",
    "\n",
    "# Filtra il dataframe per la categoria specifiche che è una \"Percentage of individuals\"\n",
    "df = df[df['unit'].isin([\"Percentage of individuals\"])]\n",
    "\n",
    "columns_to_drop = [\"ind_type\",\"unit\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Quindi le categorie saranno INDIC_IS e sono quelle per cui si è discriminato tipo religione , \n",
    "# caratteristiche ecc.\n",
    "# si suddivide per area geografica EU tipo italia \n",
    "# L'anno è il 2023 \n",
    "# Il valore è OBS_VALUE che è la percentuale di individui\n",
    "\n",
    "df = df.rename(columns={\"indic_is\": \"reason_to_discriminate\", \"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\"})\n",
    "# columns={\"ind_type\":\"Who is discriminating?\",\"indic_is\": \"reason to discriminate\", \"OBS_VALUE\": \"percentage of individual\"}\n",
    "\n",
    "# ora droppa le righe che hanno valori nulli in \"percentage of individual\" \n",
    "# , eliminando break in time series e simili\n",
    "df = df.dropna(subset=[\"percentage_of_individual\"])\n",
    "\n",
    "output_path =  \"preprocessed_data/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of individual that purchase online in the last 3 month (before 2019) (after 2019 other CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal-datasets/purchase/percentage_purchase_last_3_month_2019_before.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      4\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATAFLOW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAST UPDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_drop)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/purchase/percentage_purchase_last_3_month_2019_before.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "\n",
    "#output_path =  \"preprocessed_data/purchase/percentage_purchase_last_3_month_2019_before.csv\"\n",
    "#df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nessun valore nullo nella colonna 'population'.\n",
      "Population data cleaned and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carica i dati sulla popolazione\n",
    "population_data_path = \"original-datasets/financial/population_eu.csv\"\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "\n",
    "\n",
    "# Rinomina la colonna \"OBS_VALUE\" in \"population\"\n",
    "df_population = df_population.rename(columns={\"OBS_VALUE\": \"population\"})\n",
    "\n",
    "# Controlla se ci sono valori nulli nella colonna \"population\"\n",
    "missing_values = df_population[\"population\"].isnull().sum()\n",
    "\n",
    "if missing_values > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_values} valori nulli nella colonna 'population'.\")\n",
    "else:\n",
    "    print(\"Nessun valore nullo nella colonna 'population'.\")\n",
    "\n",
    "# Salva il dataset pulito\n",
    "cleaned_population_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "df_population.to_csv(cleaned_population_path, index=False)\n",
    "\n",
    "print(\"Population data cleaned and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completato. File salvato in: preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Percorso dei file CSV\n",
    "financial_data_path = \"original-datasets/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "population_data_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "\n",
    "# Carica il dataset finanziario\n",
    "df_financial = pd.read_csv(financial_data_path)\n",
    "\n",
    "# Rimuove le colonne inutili\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df_financial = df_financial.drop(columns=columns_to_drop)\n",
    "\n",
    "# Carica il dataset della popolazione\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "\n",
    "# Verifica che le colonne chiave esistano\n",
    "if \"geo\" not in df_financial.columns or \"geo\" not in df_population.columns:\n",
    "    raise KeyError(\"Errore: La colonna 'geo' non è presente in uno dei dataset.\")\n",
    "\n",
    "# Esegue il merge dei dataset basandosi sulla colonna 'geo'\n",
    "df_merged = pd.merge(df_financial, df_population, on=\"geo\", how=\"left\")\n",
    "\n",
    "# Elimina le righe con valori nulli nelle colonne 'population' e 'OBS_VALUE'\n",
    "df_merged = df_merged.dropna(subset=[\"population\", \"OBS_VALUE\"])\n",
    "\n",
    "# Controllo dei valori nulli nelle colonne 'population' e 'OBS_VALUE'\n",
    "missing_population = df_merged[\"population\"].isnull().sum()\n",
    "missing_obs_value = df_merged[\"OBS_VALUE\"].isnull().sum()\n",
    "\n",
    "# Stampa un avviso se ci sono valori nulli\n",
    "if missing_population > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_population} valori nulli nella colonna 'population'.\")\n",
    "if missing_obs_value > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_obs_value} valori nulli nella colonna 'OBS_VALUE'.\")\n",
    "\n",
    "# Stampa un avviso se ci sono valori nulli\n",
    "if missing_population > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_population} valori nulli nella colonna 'population'.\")\n",
    "if missing_obs_value > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_obs_value} valori nulli nella colonna 'OBS_VALUE'.\")\n",
    "\n",
    "\n",
    "# Salva il file aggiornato\n",
    "output_path = \"preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merge completato. File salvato in: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
