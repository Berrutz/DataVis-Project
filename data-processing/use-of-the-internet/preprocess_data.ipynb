{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def number_missing_values_in_coloumn(df,col):\n",
    "    num_missing = (df[col].isna() | (df[col] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in {col}: {num_missing}\")\n",
    "    \n",
    "def number_of_unique_values_in_col(df,col):\n",
    "    num_unique = df[col].nunique()\n",
    "    unique_val = df[col].unique()\n",
    "    print(f\"NUMBER of unique values in {col} : {num_unique} | Values = {unique_val} \\n \")\n",
    "    \n",
    "def drop_coloumn_df(df,columns_to_drop):\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INDIVIDUALS - FREQUENCY OF INTERNET ACCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph want to show the percentage of the daily internet access of the individuals of a selected EU country over the years from 2013 to 2024 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER of unique values in DATAFLOW : 1 | Values = ['ESTAT:TIN00092(1.0)'] \n",
      " \n",
      "NUMBER of unique values in LAST UPDATE : 1 | Values = ['17/12/24 11:00:00'] \n",
      " \n",
      "NUMBER of unique values in freq : 1 | Values = ['A:Annual'] \n",
      " \n",
      "NUMBER of unique values in indic_is : 1 | Values = ['I_IDAY:Frequency of internet access: daily'] \n",
      " \n",
      "NUMBER of unique values in unit : 1 | Values = ['PC_IND:Percentage of individuals'] \n",
      " \n",
      "NUMBER of unique values in ind_type : 1 | Values = ['IND_TOTAL:All individuals'] \n",
      " \n",
      "NUMBER of unique values in OBS_FLAG : 2 | Values = [nan 'b' 'e'] \n",
      " \n",
      "NUMBER of unique values in CONF_STATUS : 0 | Values = [nan] \n",
      " \n",
      "Numero di righe vuote in percentage: 0\n",
      "Numero di righe vuote in Country: 0\n",
      "Numero di righe vuote in Years: 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"original-datasets/frequencies/freq.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\", \"indic_is\",\n",
    "                   \"unit\",\"ind_type\",\"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "\n",
    "\n",
    "# check for how many unique values \n",
    "number_of_unique_values_in_col(df,'DATAFLOW')\n",
    "number_of_unique_values_in_col(df,\"LAST UPDATE\")\n",
    "number_of_unique_values_in_col(df,\"freq\")\n",
    "number_of_unique_values_in_col(df,\"indic_is\")\n",
    "number_of_unique_values_in_col(df,\"unit\")\n",
    "number_of_unique_values_in_col(df,\"ind_type\")\n",
    "number_of_unique_values_in_col(df,\"OBS_FLAG\")\n",
    "number_of_unique_values_in_col(df,\"CONF_STATUS\")\n",
    "\n",
    "df = df.rename(columns={\"OBS_VALUE\": \"percentage\",\"geo\":\"Country\",\"TIME_PERIOD\":\"Years\"})\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "# Modifica la colonna \"Country\" per tenere solo il testo dopo \":\"\n",
    "df[\"Country\"] = df[\"Country\"].astype(str).str.split(\":\").str[-1]\n",
    "\n",
    "# check for null values\n",
    "number_missing_values_in_coloumn(df,\"percentage\")\n",
    "number_missing_values_in_coloumn(df,\"Country\")\n",
    "number_missing_values_in_coloumn(df,\"Years\")\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"preprocessed_data/frequencies/freq.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember : In the csv if the value related to the year is not present the row is not present !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. INDIVIDUALS - INTERNET ACTIVITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to combine different CSV coming from EUROSTAT and determine which activity is performed more .\n",
    "<br>\n",
    "The Datasets are the one related to : <br>\n",
    "- The percentage of people that use internet for good and services in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for partecipation in social network in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for selling good and services in EU country from 2013 to 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_activities(df,value):\n",
    "    \n",
    "    counts = df[['CONF_STATUS']].count()\n",
    "    print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "    counts = df[['OBS_FLAG']].count()\n",
    "    print(\"OBS FLAG values: {} \".format(counts))\n",
    "    \n",
    "    # so drop the one \n",
    "    df = df[df['OBS_FLAG'].isna()]\n",
    "    \n",
    "    columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"ind_type\",\"unit\",\"CONF_STATUS\",\"OBS_FLAG\"]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    df = df.rename(columns={\"indic_is\": value,\"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\",\"TIME_PERIOD\":\"Year\"})\n",
    "    \n",
    "    # conta il numero di righe vuote nelle colonne \"indic_is,geo,TIME_PERIOD,OBS_VALUE\"\n",
    "\n",
    "    num_missing = (df['Country'].isna() | (df['Country'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Country': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['percentage_of_individual'].isna() | (df['percentage_of_individual'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'percentage_of_individual': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['Year'].isna() | (df['Year'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Year': {num_missing}\")\n",
    "    \n",
    "    num_missing = (df[value].isna() | (df[value] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in '{value}': {num_missing}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    12\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    10\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "CONF_STATUS values: CONF_STATUS    1\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    14\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 1\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"original-datasets/activities/percentage_people_good_and_services.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "file_path = \"original-datasets/activities/percentage_people_selling_good_and_services.csv\"\n",
    "df_2 = pd.read_csv(file_path)\n",
    "file_path = \"original-datasets/activities/percentage_people_partecipating_in_social_network.csv\"\n",
    "df_3 = pd.read_csv(file_path)\n",
    "\n",
    "value = \"ForWhat\"\n",
    "df = preprocess_data_activities(df,value)\n",
    "value = \"ForWhat\"\n",
    "df_2 = preprocess_data_activities(df_2,value)\n",
    "value = \"ForWhat\"\n",
    "df_3 = preprocess_data_activities(df_3,value)\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df, df_2,df_3], ignore_index=True)\n",
    "df_combined = df_combined.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "\n",
    "\n",
    "output_path =  \"preprocessed_data/activities/percentage_people_good_and_services.csv\"\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Percentual of individual of each country EU encountering Degrading Messages online in 2023 coming from NON-EU Country citizens (sub-divided for what they are discriminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS FLAG values: OBS_FLAG    3193\n",
      "dtype: int64 \n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    1\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in ind_type :\n",
      " ['Individuals who are born in another EU Member State'\n",
      " 'Individuals who are born in non-EU country'] \n",
      "\n",
      "NUMBER OF CATEGORIES in ind_type:\n",
      " 93 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\n",
      " Males, 20 to 24 years old                              621\n",
      "Individuals aged 55 to 74 with low formal education    621\n",
      "Individuals, 16 to 29 years old                        621\n",
      "Individuals aged 16-24 with medium formal education    621\n",
      "Individuals aged 16-24 with low education              621\n",
      "Name: ind_type, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in indic_is :\n",
      " ['Individuals who have encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of disability'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of political or social views'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of religion or belief'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of racial or ethnic origin'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sex'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sexual orientation (LGBTIQ identities)'] \n",
      "\n",
      "NUMBER OF CATEGORIES in indic_is:\n",
      " 8 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\n",
      " Individuals who believed that these groups of people were attacked/targeted because of disability                        7437\n",
      "Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics    7437\n",
      "Name: indic_is, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in unit :\n",
      " ['Percentage of individuals'\n",
      " 'Percentage of individuals who used internet in the last 3 months'\n",
      " 'Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'] \n",
      "\n",
      "NUMBER OF CATEGORIES in unit:\n",
      " 3 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\n",
      " Percentage of individuals                                                                                                                                                 19840\n",
      "Percentage of individuals who used internet in the last 3 months                                                                                                          19840\n",
      "Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months    17339\n",
      "Name: unit, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Austria' 'Belgium' 'Bulgaria' 'Cyprus' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'European Union - 27 countries (from 2020)' 'Finland'\n",
      " 'France' 'Croatia' 'Hungary' 'Lithuania' 'Luxembourg' 'Latvia' 'Malta'\n",
      " 'Netherlands' 'Poland' 'Portugal' 'Romania' 'Sweden' 'Slovenia'\n",
      " 'Slovakia' 'Switzerland' 'Norway'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 27 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Austria    2139\n",
      "Sweden     2139\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "counts = df[['OBS_FLAG']].count()\n",
    "print(\"OBS FLAG values: {} \".format(counts))\n",
    "\n",
    "counts = df[['CONF_STATUS']].count()\n",
    "print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "num_unique= df[['TIME_PERIOD']].nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "# quindi droppo le colonne non utili \n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"OBS_FLAG\",\"CONF_STATUS\",\"TIME_PERIOD\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"ind_type\" | 92 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA CHI è CHE VIENE DISCRIMNATO?\n",
    "\n",
    "coloumn  = df['ind_type']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in ind_type :\\n {} \\n\".format(counts[0:2]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in ind_type:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(5)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"indic_is\" | 8 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA per cosa si DISCRIMINA ?\n",
    "\n",
    "coloumn  = df['indic_is']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in indic_is :\\n {} \\n\".format(counts[:]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in indic_is:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 3 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA in che PERIODO DELL'ANNO 2023 SI DISCRIMINA\n",
    "\n",
    "coloumn  = df['unit']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in unit :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(3)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 27 CATEGORIE DIFFERENTI\n",
    "\n",
    "coloumn  = df['geo']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in geo :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in geo:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# Ora : dato che il numero di categorie in IND_TYPE è 93 \n",
    "# ( non prendo tutti gli individui ma solo 2 categorie  )\n",
    "# e il numero di categorie in INDIC_IS è 8 \n",
    "# e il numero di categorie in unit è 3 ( e droppo la colonna no , prendo solo precentage of individual quello totale\")\n",
    "\n",
    "# Filtra il dataframe per la categorie specifiche che è una \"Individuals who are born in non-EU country\"\n",
    "# RISPONDE ALLA DOMANDA CHI VIENE DISCRIMINATO ?\n",
    "df = df[df['ind_type'].isin([\"Individuals who are born in non-EU country\"])]\n",
    "\n",
    "# Filtra il dataframe per la categoria specifiche che è una \"Percentage of individuals\"\n",
    "df = df[df['unit'].isin([\"Percentage of individuals\"])]\n",
    "\n",
    "columns_to_drop = [\"ind_type\",\"unit\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Quindi le categorie saranno INDIC_IS e sono quelle per cui si è discriminato tipo religione , \n",
    "# caratteristiche ecc.\n",
    "# si suddivide per area geografica EU tipo italia \n",
    "# L'anno è il 2023 \n",
    "# Il valore è OBS_VALUE che è la percentuale di individui\n",
    "\n",
    "df = df.rename(columns={\"indic_is\": \"reason_to_discriminate\", \"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\"})\n",
    "# columns={\"ind_type\":\"Who is discriminating?\",\"indic_is\": \"reason to discriminate\", \"OBS_VALUE\": \"percentage of individual\"}\n",
    "\n",
    "# ora droppa le righe che hanno valori nulli in \"percentage of individual\" \n",
    "# , eliminando break in time series e simili\n",
    "df = df.dropna(subset=[\"percentage_of_individual\"])\n",
    "\n",
    "output_path =  \"preprocessed_data/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "- Finance : https://ec.europa.eu/eurostat/databrowser/view/isoc_ec_ifi/default/table?lang=en&category=isoc.isoc_i.isoc_iec\n",
    "- Population : https://ec.europa.eu/eurostat/databrowser/view/tps00001/default/table?lang=en&category=t_demo.t_demo_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Percentage of individual that purchase online in the last 3 month in Europe Continent (before 2019) (after 2019 other CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last online purchase: in the last 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df):\n",
    "    counts = df[['CONF_STATUS']].count()\n",
    "    print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "    df = df[df['OBS_FLAG'].isna()]\n",
    "\n",
    "    counts = df[['OBS_FLAG']].count()\n",
    "    print(\"OBS FLAG values: {} \".format(counts))\n",
    "\n",
    "    columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"indic_is\",\"ind_type\",\"unit\",\"CONF_STATUS\",\"OBS_FLAG\"]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    num_unique= df[['TIME_PERIOD']].nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "    # conto il numero di valori differenti nelle colonne \"geo\" | 44 CATEGORIE DIFFERENTI in Unione Europea \n",
    "\n",
    "    coloumn  = df['geo']\n",
    "    counts = coloumn.unique()\n",
    "    print(\"\\nVALORI in geo :\\n {} \\n\".format(counts))\n",
    "\n",
    "    num_unique = coloumn.nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in geo:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    value_counts = coloumn.value_counts().head(4)\n",
    "    print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "    # conto il numero di valori differenti nelle colonne \"TIME_PERIOD\" | 10 CATEGORIE DIFFERENTI dal 2010 al 2019\n",
    "\n",
    "    coloumn  = df['TIME_PERIOD']\n",
    "    counts = sorted(coloumn.unique())\n",
    "    print(\"\\nVALORI in TIME_PERIOD :\\n {} \\n\".format(counts))\n",
    "\n",
    "    num_unique = coloumn.nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in TIME_PERIOD:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    value_counts = coloumn.value_counts().head(4)\n",
    "    print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "\n",
    "    df = df.rename(columns={\"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\",\"TIME_PERIOD\":\"Year\"})\n",
    "    # conta il numero di righe vuote nelle colonne \"geo,TIME_PERIOD,OBS_VALUE\"\n",
    "\n",
    "    num_missing = (df['Country'].isna() | (df['Country'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Country': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['percentage_of_individual'].isna() | (df['percentage_of_individual'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'percentage_of_individual': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['Year'].isna() | (df['Year'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Year': {num_missing}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    10\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Albania' 'Austria' 'Bosnia and Herzegovina' 'Belgium' 'Bulgaria'\n",
      " 'Switzerland' 'Cyprus' 'Czechia' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'Spain' 'European Union - 15 countries (1995-2004)'\n",
      " 'European Union - 25 countries (2004-2006)'\n",
      " 'European Union - 27 countries (2007-2013)'\n",
      " 'European Union - 27 countries (from 2020)'\n",
      " 'European Union - 28 countries (2013-2020)' 'Finland' 'France' 'Croatia'\n",
      " 'Hungary' 'Ireland' 'Iceland' 'Italy' 'Lithuania' 'Luxembourg' 'Latvia'\n",
      " 'Montenegro' 'North Macedonia' 'Malta' 'Netherlands' 'Norway' 'Poland'\n",
      " 'Portugal' 'Romania' 'Serbia' 'Sweden' 'Slovenia' 'Slovakia' 'Türkiye'\n",
      " 'United Kingdom' 'Kosovo*'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 44 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Hungary                                      10\n",
      "European Union - 27 countries (from 2020)    10\n",
      "Portugal                                     10\n",
      "Poland                                       10\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in TIME_PERIOD :\n",
      " [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019] \n",
      "\n",
      "NUMBER OF CATEGORIES in TIME_PERIOD:\n",
      " 10 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\n",
      " 2018    41\n",
      "2019    41\n",
      "2017    40\n",
      "2010    38\n",
      "Name: TIME_PERIOD, dtype: int64 \n",
      "\n",
      "############################\n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    5\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Albania' 'Austria' 'Bosnia and Herzegovina' 'Belgium' 'Bulgaria'\n",
      " 'Switzerland' 'Cyprus' 'Czechia' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'Spain' 'European Union - 27 countries (from 2020)'\n",
      " 'Finland' 'France' 'Croatia' 'Hungary' 'Ireland' 'Iceland' 'Italy'\n",
      " 'Lithuania' 'Luxembourg' 'Latvia' 'Montenegro' 'North Macedonia' 'Malta'\n",
      " 'Netherlands' 'Norway' 'Poland' 'Portugal' 'Romania' 'Serbia' 'Sweden'\n",
      " 'Slovenia' 'Slovakia' 'Türkiye' 'United Kingdom' 'Kosovo*'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 40 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Hungary    5\n",
      "Malta      5\n",
      "Austria    5\n",
      "Italy      5\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in TIME_PERIOD :\n",
      " [2020, 2021, 2022, 2023, 2024] \n",
      "\n",
      "NUMBER OF CATEGORIES in TIME_PERIOD:\n",
      " 5 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\n",
      " 2020    36\n",
      "2023    36\n",
      "2024    35\n",
      "2021    34\n",
      "Name: TIME_PERIOD, dtype: int64 \n",
      "\n",
      "############################\n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/purchase/percentage_purchase_last_3_month_2019_before.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "file_path = \"original-datasets/purchase/percentage_purchase_last_3_month_2019_on.csv\"\n",
    "df_new = pd.read_csv(file_path)\n",
    "df_new = preprocess_data(df_new)\n",
    "\n",
    "# combino i due dataset\n",
    "df_combined = pd.concat([df, df_new], ignore_index=True)\n",
    "df_combined = df_combined.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "\n",
    "output_path =  \"preprocessed_data/purchase/percentage_purchase_last_3_month_2019.csv\"\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Financial Activities - Bubble Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to combine 2 CSV coming from EUROSTAT and determine the percentage of individuals that invest an on what depending on the country \n",
    "<br>\n",
    "The Datasets are the one related to : <br>\n",
    "- The percentage of people that use bought or sold shares or other investiment from 2013 to 2024 in the European Continent .\n",
    "- The percentage of people living on the selected country \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di righe vuote in Country: 0\n",
      "Numero di righe vuote in population: 0\n",
      "Numero di righe vuote in Years: 0\n",
      "NUMBER of unique values in DATAFLOW : 1 | Values = ['ESTAT:TPS00001(1.0)'] \n",
      " \n",
      "NUMBER of unique values in LAST UPDATE : 1 | Values = ['09/01/25 23:00:00'] \n",
      " \n",
      "NUMBER of unique values in freq : 1 | Values = ['Annual'] \n",
      " \n",
      "NUMBER of unique values in indic_de : 1 | Values = ['Population on 1 January - total'] \n",
      " \n",
      "NUMBER of unique values in OBS_FLAG : 6 | Values = [nan 'e' 'p' 'b' 'ep' 'be' 'bep'] \n",
      " \n",
      "NUMBER of unique values in CONF_STATUS : 0 | Values = [nan] \n",
      " \n",
      "Population data cleaned and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Carica i dati sulla popolazione\n",
    "population_data_path = \"original-datasets/financial/population_eu.csv\"\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "\n",
    "\n",
    "# Rename col\n",
    "df_population = df_population.rename(columns={\"OBS_VALUE\": \"population\",\"geo\":\"Country\",\"TIME_PERIOD\":\"Years\"})\n",
    "#print(df_population.head(1))\n",
    "\n",
    "# check for null values\n",
    "number_missing_values_in_coloumn(df_population,\"Country\")\n",
    "number_missing_values_in_coloumn(df_population,\"population\")\n",
    "number_missing_values_in_coloumn(df_population,\"Years\")\n",
    "\n",
    "# check for how many unique values \n",
    "number_of_unique_values_in_col(df_population,'DATAFLOW')\n",
    "number_of_unique_values_in_col(df_population,\"LAST UPDATE\")\n",
    "number_of_unique_values_in_col(df_population,\"freq\")\n",
    "number_of_unique_values_in_col(df_population,\"indic_de\")\n",
    "number_of_unique_values_in_col(df_population,\"OBS_FLAG\")\n",
    "number_of_unique_values_in_col(df_population,\"CONF_STATUS\")\n",
    "\n",
    "\n",
    "# drop coloumn DATAFLOW,LAST UPDATE,freq,indic_de e OBS_FLAG,CONF_STATUS\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"indic_de\",\"OBS_FLAG\",\"CONF_STATUS\"]\n",
    "df_population = drop_coloumn_df(df_population,columns_to_drop)\n",
    "\n",
    "# TODO: Interpolate data from 2013 and 2024\n",
    "all_years = list(range(2013, 2025))\n",
    "\n",
    "# Interpolazione per ogni paese\n",
    "def interpolate_country(group):\n",
    "    group = group.set_index(\"Years\").reindex(all_years)\n",
    "    group[\"Country\"] = group[\"Country\"].ffill()  # Riempie il nome del paese\n",
    "    group[\"population\"] = group[\"population\"].interpolate(method=\"linear\").round().astype(\"Int64\")  # Interpola e arrotonda a intero\n",
    "    return group.reset_index()\n",
    "\n",
    "df_population = df_population.groupby(\"Country\").apply(interpolate_country)\n",
    "\n",
    "\n",
    "df_population = df_population.reset_index(drop=True)[[\"Country\", \"Years\", \"population\"]]\n",
    "\n",
    "# Salva il dataset pulito\n",
    "cleaned_population_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "df_population.to_csv(cleaned_population_path, index=False)\n",
    "\n",
    "print(\"Population data cleaned and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER of unique values in DATAFLOW : 1 | Values = ['ESTAT:ISOC_EC_IFI(1.0)'] \n",
      " \n",
      "NUMBER of unique values in LAST UPDATE : 1 | Values = ['16/06/24 23:00:00'] \n",
      " \n",
      "NUMBER of unique values in freq : 1 | Values = ['Annual'] \n",
      " \n",
      "NUMBER of unique values in ind_type : 1 | Values = ['All individuals'] \n",
      " \n",
      "NUMBER of unique values in indic_is : 1 | Values = ['Individuals bought or sold shares, bonds, funds or other investment services over the internet'] \n",
      " \n",
      "Numero di righe vuote in unit: 0\n",
      "NUMBER of unique values in OBS_FLAG : 2 | Values = [nan 'u' 'b'] \n",
      " \n",
      "NUMBER of unique values in CONF_STATUS : 0 | Values = [nan] \n",
      " \n",
      "Attenzione! Ci sono 0 valori nulli nella colonna 'population'.\n",
      "Attenzione! Ci sono 0 valori nulli nella colonna 'percentage'.\n",
      "Merge completato. File salvato in: preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\n"
     ]
    }
   ],
   "source": [
    "financial_data_path = \"original-datasets/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "population_data_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "df_financial = pd.read_csv(financial_data_path)\n",
    "\n",
    "# check for drop column\n",
    "number_of_unique_values_in_col(df_financial,'DATAFLOW')\n",
    "number_of_unique_values_in_col(df_financial,\"LAST UPDATE\")\n",
    "number_of_unique_values_in_col(df_financial,\"freq\")\n",
    "number_of_unique_values_in_col(df_financial,\"ind_type\")\n",
    "number_of_unique_values_in_col(df_financial,\"indic_is\")\n",
    "number_missing_values_in_coloumn(df_financial,\"unit\")\n",
    "number_of_unique_values_in_col(df_financial,\"OBS_FLAG\")\n",
    "number_of_unique_values_in_col(df_financial,\"CONF_STATUS\")\n",
    "\n",
    "# Remove the not used col\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\", \"ind_type\",\"indic_is\",\"unit\" ,\"OBS_FLAG\",\"CONF_STATUS\"]\n",
    "df_financial = df_financial.drop(columns=columns_to_drop)\n",
    "\n",
    "df_financial = df_financial.rename(columns={\"OBS_VALUE\": \"percentage\",\"geo\":\"Country\",\"TIME_PERIOD\":\"Years\"})\n",
    "\n",
    "df_financial.head(1)\n",
    "\n",
    "# MERGE \n",
    "\n",
    "# Verifica che le colonne chiave esistano\n",
    "if \"Country\" not in df_financial.columns or \"Country\" not in df_population.columns:\n",
    "    raise KeyError(\"Errore: La colonna 'Country' non è presente in uno dei dataset.\")\n",
    "\n",
    "# Verifica che le colonne chiave esistano\n",
    "if \"Years\" not in df_financial.columns or \"Years\" not in df_population.columns:\n",
    "    raise KeyError(\"Errore: La colonna 'Years' non è presente in uno dei dataset.\")\n",
    "\n",
    "df_merged = pd.merge(df_population, df_financial, on=[\"Country\", \"Years\"], how=\"left\")\n",
    "\n",
    "# Anche se il merge produce valori Nan essi vengono scartati da questo comando\n",
    "df_merged = df_merged.dropna(subset=[\"population\", \"percentage\"])\n",
    "\n",
    "missing_population = df_merged[\"population\"].isnull().sum()\n",
    "missing_obs_value = df_merged[\"percentage\"].isnull().sum()\n",
    "\n",
    "# Stampa un avviso se ci sono valori nulli\n",
    "if missing_population >= 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_population} valori nulli nella colonna 'population'.\")\n",
    "if missing_obs_value >= 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_obs_value} valori nulli nella colonna 'percentage'.\")\n",
    "    \n",
    "# Salva il file aggiornato\n",
    "output_path = \"preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merge completato. File salvato in: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to create a Bubble Chart in which the :\n",
    "- dimension of the bubble : <br>\n",
    "is related to the RATIO between percentage and size of the country , just to give more enlight which country is the one that is contributing more in number of people in the financial world .\n",
    "- color of the bubble : is related to the country \n",
    "- number of the bubble : is related to the years ( so there are different bubble of color blue for example) .\n",
    "\n",
    "- The position in the Chart of the Bubble is free and dinamically arranged\n",
    "\n",
    "So the general idea of this chart is to show which country in which year have the biggest number of individual that contribute to the financial world. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
