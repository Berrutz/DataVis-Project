{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INDIVIDUALS - FREQUENCY OF INTERNET ACCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indic_is ( Statistic Indicator )\n",
    "I_IDAY: Frequency of internet access: daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC_IND (Unit of Measure )\n",
    "PC_IND: Percentage of individuals (and not for example enterprise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IND_TOTAL:All individuals ( and not only male or female )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_path = \"original-datasets/freq/freq.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "output_path =  \"original-datasets/freq/freq.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember : In the csv if the value related to the year is not present the row is not present !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. INDIVIDUALS - INTERNET ACTIVITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to combine different CSV coming from EUROSTAT and determine which activity is performed more .\n",
    "<br>\n",
    "The Datasets are the one related to : <br>\n",
    "- The percentage of people that use internet for good and services in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for partecipation in social network in EU country from 2013 to 2024\n",
    "- The percentage of people that use internet for selling good and services in EU country from 2013 to 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_internet(df,value):\n",
    "    \n",
    "    counts = df[['CONF_STATUS']].count()\n",
    "    print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "    counts = df[['OBS_FLAG']].count()\n",
    "    print(\"OBS FLAG values: {} \".format(counts))\n",
    "    \n",
    "    # so drop the one \n",
    "    df = df[df['OBS_FLAG'].isna()]\n",
    "    \n",
    "    columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"ind_type\",\"unit\",\"CONF_STATUS\",\"OBS_FLAG\"]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    df = df.rename(columns={\"indic_is\": value,\"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\",\"TIME_PERIOD\":\"Year\"})\n",
    "    \n",
    "    # conta il numero di righe vuote nelle colonne \"indic_is,geo,TIME_PERIOD,OBS_VALUE\"\n",
    "\n",
    "    num_missing = (df['Country'].isna() | (df['Country'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Country': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['percentage_of_individual'].isna() | (df['percentage_of_individual'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'percentage_of_individual': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['Year'].isna() | (df['Year'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Year': {num_missing}\")\n",
    "    \n",
    "    num_missing = (df[value].isna() | (df[value] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in '{value}': {num_missing}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    12\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    10\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "CONF_STATUS values: CONF_STATUS    1\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    14\n",
      "dtype: int64 \n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 1\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Numero di righe vuote in 'ForWhat': 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"original-datasets/activities/percentage_people_good_and_services.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "file_path = \"original-datasets/activities/percentage_people_selling_good_and_services.csv\"\n",
    "df_2 = pd.read_csv(file_path)\n",
    "file_path = \"original-datasets/activities/percentage_people_partecipating_in_social_network.csv\"\n",
    "df_3 = pd.read_csv(file_path)\n",
    "\n",
    "value = \"ForWhat\"\n",
    "df = preprocess_data_internet(df,value)\n",
    "value = \"ForWhat\"\n",
    "df_2 = preprocess_data_internet(df_2,value)\n",
    "value = \"ForWhat\"\n",
    "df_3 = preprocess_data_internet(df_3,value)\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df, df_2,df_3], ignore_index=True)\n",
    "df_combined = df_combined.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "\n",
    "\n",
    "output_path =  \"preprocessed_data/activities/percentage_people_good_and_services.csv\"\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Percentual of individual of each country EU encountering Degrading Messages online in 2023 coming from NON-EU Country citizens (sub-divided for what they are discriminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS FLAG values: OBS_FLAG    3193\n",
      "dtype: int64 \n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    1\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in ind_type :\n",
      " ['Individuals who are born in another EU Member State'\n",
      " 'Individuals who are born in non-EU country'] \n",
      "\n",
      "NUMBER OF CATEGORIES in ind_type:\n",
      " 93 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\n",
      " Males, 20 to 24 years old                              621\n",
      "Individuals aged 55 to 74 with low formal education    621\n",
      "Individuals, 16 to 29 years old                        621\n",
      "Individuals aged 16-24 with medium formal education    621\n",
      "Individuals aged 16-24 with low education              621\n",
      "Name: ind_type, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in indic_is :\n",
      " ['Individuals who have encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of disability'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of political or social views'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of religion or belief'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of racial or ethnic origin'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sex'\n",
      " 'Individuals who believed that these groups of people were attacked/targeted because of sexual orientation (LGBTIQ identities)'] \n",
      "\n",
      "NUMBER OF CATEGORIES in indic_is:\n",
      " 8 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\n",
      " Individuals who believed that these groups of people were attacked/targeted because of disability                        7437\n",
      "Individuals who believed that these groups of people were attacked/targeted because of other personal characteristics    7437\n",
      "Name: indic_is, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in unit :\n",
      " ['Percentage of individuals'\n",
      " 'Percentage of individuals who used internet in the last 3 months'\n",
      " 'Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months'] \n",
      "\n",
      "NUMBER OF CATEGORIES in unit:\n",
      " 3 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\n",
      " Percentage of individuals                                                                                                                                                 19840\n",
      "Percentage of individuals who used internet in the last 3 months                                                                                                          19840\n",
      "Percentage of individuals who encountered messages online that were considered to be hostile or degrading towards groups of people or individuals in the last 3 months    17339\n",
      "Name: unit, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Austria' 'Belgium' 'Bulgaria' 'Cyprus' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'European Union - 27 countries (from 2020)' 'Finland'\n",
      " 'France' 'Croatia' 'Hungary' 'Lithuania' 'Luxembourg' 'Latvia' 'Malta'\n",
      " 'Netherlands' 'Poland' 'Portugal' 'Romania' 'Sweden' 'Slovenia'\n",
      " 'Slovakia' 'Switzerland' 'Norway'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 27 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Austria    2139\n",
      "Sweden     2139\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "counts = df[['OBS_FLAG']].count()\n",
    "print(\"OBS FLAG values: {} \".format(counts))\n",
    "\n",
    "counts = df[['CONF_STATUS']].count()\n",
    "print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "num_unique= df[['TIME_PERIOD']].nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "# quindi droppo le colonne non utili \n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"OBS_FLAG\",\"CONF_STATUS\",\"TIME_PERIOD\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"ind_type\" | 92 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA CHI è CHE VIENE DISCRIMNATO?\n",
    "\n",
    "coloumn  = df['ind_type']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in ind_type :\\n {} \\n\".format(counts[0:2]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in ind_type:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(5)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column ind_type:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"indic_is\" | 8 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA per cosa si DISCRIMINA ?\n",
    "\n",
    "coloumn  = df['indic_is']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in indic_is :\\n {} \\n\".format(counts[:]))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in indic_is:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column indic_is:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 3 CATEGORIE DIFFERENTI\n",
    "# RISPONDE ALLA DOMANDA in che PERIODO DELL'ANNO 2023 SI DISCRIMINA\n",
    "\n",
    "coloumn  = df['unit']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in unit :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(3)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the column unit:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# conto il numero di valori differenti nelle colonne \"unit\" | 27 CATEGORIE DIFFERENTI\n",
    "\n",
    "coloumn  = df['geo']\n",
    "counts = coloumn.unique()\n",
    "print(\"\\nVALORI in geo :\\n {} \\n\".format(counts))\n",
    "\n",
    "num_unique = coloumn.nunique()\n",
    "print(\"NUMBER OF CATEGORIES in geo:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "value_counts = coloumn.value_counts().head(2)\n",
    "print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "print(\"############################\")\n",
    "\n",
    "# Ora : dato che il numero di categorie in IND_TYPE è 93 \n",
    "# ( non prendo tutti gli individui ma solo 2 categorie  )\n",
    "# e il numero di categorie in INDIC_IS è 8 \n",
    "# e il numero di categorie in unit è 3 ( e droppo la colonna no , prendo solo precentage of individual quello totale\")\n",
    "\n",
    "# Filtra il dataframe per la categorie specifiche che è una \"Individuals who are born in non-EU country\"\n",
    "# RISPONDE ALLA DOMANDA CHI VIENE DISCRIMINATO ?\n",
    "df = df[df['ind_type'].isin([\"Individuals who are born in non-EU country\"])]\n",
    "\n",
    "# Filtra il dataframe per la categoria specifiche che è una \"Percentage of individuals\"\n",
    "df = df[df['unit'].isin([\"Percentage of individuals\"])]\n",
    "\n",
    "columns_to_drop = [\"ind_type\",\"unit\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Quindi le categorie saranno INDIC_IS e sono quelle per cui si è discriminato tipo religione , \n",
    "# caratteristiche ecc.\n",
    "# si suddivide per area geografica EU tipo italia \n",
    "# L'anno è il 2023 \n",
    "# Il valore è OBS_VALUE che è la percentuale di individui\n",
    "\n",
    "df = df.rename(columns={\"indic_is\": \"reason_to_discriminate\", \"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\"})\n",
    "# columns={\"ind_type\":\"Who is discriminating?\",\"indic_is\": \"reason to discriminate\", \"OBS_VALUE\": \"percentage of individual\"}\n",
    "\n",
    "# ora droppa le righe che hanno valori nulli in \"percentage of individual\" \n",
    "# , eliminando break in time series e simili\n",
    "df = df.dropna(subset=[\"percentage_of_individual\"])\n",
    "\n",
    "output_path =  \"preprocessed_data/degrading/percentage_people_degrading_online_mex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Percentage of individual that purchase online in the last 3 month in Europe Continent (before 2019) (after 2019 other CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last online purchase: in the last 3 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(df):\n",
    "    counts = df[['CONF_STATUS']].count()\n",
    "    print(\"CONF_STATUS values: {} \".format(counts))\n",
    "\n",
    "    df = df[df['OBS_FLAG'].isna()]\n",
    "\n",
    "    counts = df[['OBS_FLAG']].count()\n",
    "    print(\"OBS FLAG values: {} \".format(counts))\n",
    "\n",
    "    columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"freq\",\"indic_is\",\"ind_type\",\"unit\",\"CONF_STATUS\",\"OBS_FLAG\"]\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    num_unique= df[['TIME_PERIOD']].nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in unit:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "    # conto il numero di valori differenti nelle colonne \"geo\" | 44 CATEGORIE DIFFERENTI in Unione Europea \n",
    "\n",
    "    coloumn  = df['geo']\n",
    "    counts = coloumn.unique()\n",
    "    print(\"\\nVALORI in geo :\\n {} \\n\".format(counts))\n",
    "\n",
    "    num_unique = coloumn.nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in geo:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    value_counts = coloumn.value_counts().head(4)\n",
    "    print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "    # conto il numero di valori differenti nelle colonne \"TIME_PERIOD\" | 10 CATEGORIE DIFFERENTI dal 2010 al 2019\n",
    "\n",
    "    coloumn  = df['TIME_PERIOD']\n",
    "    counts = sorted(coloumn.unique())\n",
    "    print(\"\\nVALORI in TIME_PERIOD :\\n {} \\n\".format(counts))\n",
    "\n",
    "    num_unique = coloumn.nunique()\n",
    "    print(\"NUMBER OF CATEGORIES in TIME_PERIOD:\\n {} \\n\".format(num_unique))\n",
    "\n",
    "    value_counts = coloumn.value_counts().head(4)\n",
    "    print(\"COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\\n {} \\n\".format(value_counts))\n",
    "\n",
    "\n",
    "    print(\"############################\")\n",
    "\n",
    "\n",
    "    df = df.rename(columns={\"geo\":\"Country\", \"OBS_VALUE\": \"percentage_of_individual\",\"TIME_PERIOD\":\"Year\"})\n",
    "    # conta il numero di righe vuote nelle colonne \"geo,TIME_PERIOD,OBS_VALUE\"\n",
    "\n",
    "    num_missing = (df['Country'].isna() | (df['Country'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Country': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['percentage_of_individual'].isna() | (df['percentage_of_individual'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'percentage_of_individual': {num_missing}\")\n",
    "\n",
    "    num_missing = (df['Year'].isna() | (df['Year'] == '')).sum()\n",
    "    print(f\"Numero di righe vuote in 'Year': {num_missing}\")\n",
    "\n",
    "    df = df.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    10\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Albania' 'Austria' 'Bosnia and Herzegovina' 'Belgium' 'Bulgaria'\n",
      " 'Switzerland' 'Cyprus' 'Czechia' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'Spain' 'European Union - 15 countries (1995-2004)'\n",
      " 'European Union - 25 countries (2004-2006)'\n",
      " 'European Union - 27 countries (2007-2013)'\n",
      " 'European Union - 27 countries (from 2020)'\n",
      " 'European Union - 28 countries (2013-2020)' 'Finland' 'France' 'Croatia'\n",
      " 'Hungary' 'Ireland' 'Iceland' 'Italy' 'Lithuania' 'Luxembourg' 'Latvia'\n",
      " 'Montenegro' 'North Macedonia' 'Malta' 'Netherlands' 'Norway' 'Poland'\n",
      " 'Portugal' 'Romania' 'Serbia' 'Sweden' 'Slovenia' 'Slovakia' 'Türkiye'\n",
      " 'United Kingdom' 'Kosovo*'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 44 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Hungary                                      10\n",
      "European Union - 27 countries (from 2020)    10\n",
      "Portugal                                     10\n",
      "Poland                                       10\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in TIME_PERIOD :\n",
      " [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019] \n",
      "\n",
      "NUMBER OF CATEGORIES in TIME_PERIOD:\n",
      " 10 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\n",
      " 2018    41\n",
      "2019    41\n",
      "2017    40\n",
      "2010    38\n",
      "Name: TIME_PERIOD, dtype: int64 \n",
      "\n",
      "############################\n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "CONF_STATUS values: CONF_STATUS    0\n",
      "dtype: int64 \n",
      "OBS FLAG values: OBS_FLAG    0\n",
      "dtype: int64 \n",
      "NUMBER OF CATEGORIES in unit:\n",
      " TIME_PERIOD    5\n",
      "dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in geo :\n",
      " ['Albania' 'Austria' 'Bosnia and Herzegovina' 'Belgium' 'Bulgaria'\n",
      " 'Switzerland' 'Cyprus' 'Czechia' 'Germany' 'Denmark'\n",
      " 'Euro area (EA11-1999, EA12-2001, EA13-2007, EA15-2008, EA16-2009, EA17-2011, EA18-2014, EA19-2015, EA20-2023)'\n",
      " 'Estonia' 'Greece' 'Spain' 'European Union - 27 countries (from 2020)'\n",
      " 'Finland' 'France' 'Croatia' 'Hungary' 'Ireland' 'Iceland' 'Italy'\n",
      " 'Lithuania' 'Luxembourg' 'Latvia' 'Montenegro' 'North Macedonia' 'Malta'\n",
      " 'Netherlands' 'Norway' 'Poland' 'Portugal' 'Romania' 'Serbia' 'Sweden'\n",
      " 'Slovenia' 'Slovakia' 'Türkiye' 'United Kingdom' 'Kosovo*'] \n",
      "\n",
      "NUMBER OF CATEGORIES in geo:\n",
      " 40 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn geo:\n",
      " Hungary    5\n",
      "Malta      5\n",
      "Austria    5\n",
      "Italy      5\n",
      "Name: geo, dtype: int64 \n",
      "\n",
      "############################\n",
      "\n",
      "VALORI in TIME_PERIOD :\n",
      " [2020, 2021, 2022, 2023, 2024] \n",
      "\n",
      "NUMBER OF CATEGORIES in TIME_PERIOD:\n",
      " 5 \n",
      "\n",
      "COUNT FOR EACH CATEGORY OF THE ROWS in the dataset for the coloumn TIME_PERIOD:\n",
      " 2020    36\n",
      "2023    36\n",
      "2024    35\n",
      "2021    34\n",
      "Name: TIME_PERIOD, dtype: int64 \n",
      "\n",
      "############################\n",
      "Numero di righe vuote in 'Country': 0\n",
      "Numero di righe vuote in 'percentage_of_individual': 0\n",
      "Numero di righe vuote in 'Year': 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file_path = \"original-datasets/purchase/percentage_purchase_last_3_month_2019_before.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = preprocess_data(df)\n",
    "\n",
    "file_path = \"original-datasets/purchase/percentage_purchase_last_3_month_2019_on.csv\"\n",
    "df_new = pd.read_csv(file_path)\n",
    "df_new = preprocess_data(df_new)\n",
    "\n",
    "# combino i due dataset\n",
    "df_combined = pd.concat([df, df_new], ignore_index=True)\n",
    "df_combined = df_combined.sort_values(by=[\"Country\",\"Year\"], ascending=[True,True])\n",
    "\n",
    "output_path =  \"preprocessed_data/purchase/percentage_purchase_last_3_month_2019.csv\"\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Financial Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nessun valore nullo nella colonna 'population'.\n",
      "Population data cleaned and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carica i dati sulla popolazione\n",
    "population_data_path = \"original-datasets/financial/population_eu.csv\"\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "\n",
    "\n",
    "# Rinomina la colonna \"OBS_VALUE\" in \"population\"\n",
    "df_population = df_population.rename(columns={\"OBS_VALUE\": \"population\"})\n",
    "\n",
    "# Controlla se ci sono valori nulli nella colonna \"population\"\n",
    "missing_values = df_population[\"population\"].isnull().sum()\n",
    "\n",
    "if missing_values > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_values} valori nulli nella colonna 'population'.\")\n",
    "else:\n",
    "    print(\"Nessun valore nullo nella colonna 'population'.\")\n",
    "\n",
    "# Salva il dataset pulito\n",
    "cleaned_population_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "df_population.to_csv(cleaned_population_path, index=False)\n",
    "\n",
    "print(\"Population data cleaned and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completato. File salvato in: preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Percorso dei file CSV\n",
    "financial_data_path = \"original-datasets/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "population_data_path = \"preprocessed_data/financial/population_eu.csv\"\n",
    "\n",
    "# Carica il dataset finanziario\n",
    "df_financial = pd.read_csv(financial_data_path)\n",
    "\n",
    "# Rimuove le colonne inutili\n",
    "columns_to_drop = [\"DATAFLOW\", \"LAST UPDATE\", \"OBS_FLAG\", \"CONF_STATUS\"]\n",
    "df_financial = df_financial.drop(columns=columns_to_drop)\n",
    "\n",
    "# Carica il dataset della popolazione\n",
    "df_population = pd.read_csv(population_data_path)\n",
    "\n",
    "# Verifica che le colonne chiave esistano\n",
    "if \"geo\" not in df_financial.columns or \"geo\" not in df_population.columns:\n",
    "    raise KeyError(\"Errore: La colonna 'geo' non è presente in uno dei dataset.\")\n",
    "\n",
    "# Esegue il merge dei dataset basandosi sulla colonna 'geo'\n",
    "df_merged = pd.merge(df_financial, df_population, on=\"geo\", how=\"left\")\n",
    "\n",
    "# Elimina le righe con valori nulli nelle colonne 'population' e 'OBS_VALUE'\n",
    "df_merged = df_merged.dropna(subset=[\"population\", \"OBS_VALUE\"])\n",
    "\n",
    "# Controllo dei valori nulli nelle colonne 'population' e 'OBS_VALUE'\n",
    "missing_population = df_merged[\"population\"].isnull().sum()\n",
    "missing_obs_value = df_merged[\"OBS_VALUE\"].isnull().sum()\n",
    "\n",
    "# Stampa un avviso se ci sono valori nulli\n",
    "if missing_population > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_population} valori nulli nella colonna 'population'.\")\n",
    "if missing_obs_value > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_obs_value} valori nulli nella colonna 'OBS_VALUE'.\")\n",
    "\n",
    "# Stampa un avviso se ci sono valori nulli\n",
    "if missing_population > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_population} valori nulli nella colonna 'population'.\")\n",
    "if missing_obs_value > 0:\n",
    "    print(f\"Attenzione! Ci sono {missing_obs_value} valori nulli nella colonna 'OBS_VALUE'.\")\n",
    "\n",
    "\n",
    "# Salva il file aggiornato\n",
    "output_path = \"preprocessed_data/financial/percentage_Individuals_bought_or_sold shares_or_other_investiment.csv\"\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Merge completato. File salvato in: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
